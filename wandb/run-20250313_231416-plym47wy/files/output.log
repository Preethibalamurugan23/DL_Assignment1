
Training with optimizer: adam
Epoch 0, Loss: 0.5467
Epoch 1, Loss: 0.4955
Epoch 2, Loss: 0.4581
Epoch 3, Loss: 0.4373
Epoch 4, Loss: 0.4265
Epoch 5, Loss: 0.4088
Epoch 6, Loss: 0.4000
Epoch 7, Loss: 0.3896
Epoch 8, Loss: 0.3954
Epoch 9, Loss: 0.3760
Epoch 10, Loss: 0.3703
Epoch 11, Loss: 0.3615
Epoch 12, Loss: 0.3560
Epoch 13, Loss: 0.3502
Epoch 14, Loss: 0.3435
Epoch 15, Loss: 0.3395
Epoch 16, Loss: 0.3372
Epoch 17, Loss: 0.3356
Epoch 18, Loss: 0.3264
Epoch 19, Loss: 0.3274
Epoch 20, Loss: 0.3197
Epoch 21, Loss: 0.3188
Epoch 22, Loss: 0.3113
Epoch 23, Loss: 0.3087
Epoch 24, Loss: 0.3040
Epoch 25, Loss: 0.3003
Epoch 26, Loss: 0.2963
Epoch 27, Loss: 0.2926
Epoch 28, Loss: 0.2994
Epoch 29, Loss: 0.2886
Epoch 30, Loss: 0.2851
Epoch 31, Loss: 0.2803
Epoch 32, Loss: 0.2868
Epoch 33, Loss: 0.2778
Epoch 34, Loss: 0.2702
Epoch 35, Loss: 0.2679
Epoch 36, Loss: 0.2717
Epoch 37, Loss: 0.2727
Epoch 38, Loss: 0.2608
Epoch 39, Loss: 0.2729
Epoch 40, Loss: 0.2636
Epoch 41, Loss: 0.2585
Epoch 42, Loss: 0.2553
Epoch 43, Loss: 0.2488
Epoch 44, Loss: 0.2485
Epoch 45, Loss: 0.2416
Epoch 46, Loss: 0.2459
Epoch 47, Loss: 0.2383
Epoch 48, Loss: 0.2383
Epoch 49, Loss: 0.2315
