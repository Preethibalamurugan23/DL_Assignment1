
Training with optimizer: nadam
Epoch 0, Loss: 0.5852
Epoch 1, Loss: 0.5058
Epoch 2, Loss: 0.6275
Epoch 3, Loss: 0.6328
Epoch 4, Loss: 0.6706
Epoch 5, Loss: 0.7591
Epoch 6, Loss: 0.7442
Epoch 7, Loss: 0.8319
Epoch 8, Loss: 0.9203
Epoch 9, Loss: 0.7916
Epoch 10, Loss: 0.7820
Epoch 11, Loss: 0.9764
Epoch 12, Loss: 0.7481
Epoch 13, Loss: 0.8556
Epoch 14, Loss: 0.9353
Epoch 15, Loss: 0.7983
Epoch 16, Loss: 0.9452
Epoch 17, Loss: 0.8401
Epoch 18, Loss: 0.9364
Epoch 19, Loss: 0.8841
Epoch 20, Loss: 0.9987
Epoch 21, Loss: 1.0103
Epoch 22, Loss: 1.0300
Epoch 23, Loss: 1.0316
Epoch 24, Loss: 0.9406
Epoch 25, Loss: 1.0193
Epoch 26, Loss: 1.0182
Epoch 27, Loss: 1.1604
Epoch 28, Loss: 0.8502
Epoch 29, Loss: 1.1221
Epoch 30, Loss: 1.0832
Epoch 31, Loss: 0.9493
Epoch 32, Loss: 1.1490
Epoch 33, Loss: 1.1323
Epoch 34, Loss: 0.9520
Epoch 35, Loss: 1.1950
Epoch 36, Loss: 1.3143
Epoch 37, Loss: 1.1078
Epoch 38, Loss: 1.0971
Epoch 39, Loss: 1.3412
Epoch 40, Loss: 1.1033
Epoch 41, Loss: 1.0924
Epoch 42, Loss: 1.3840
Epoch 43, Loss: 1.1224
Epoch 44, Loss: 0.9980
Epoch 45, Loss: 1.0122
Epoch 46, Loss: 1.6008
Epoch 47, Loss: 1.1656
Epoch 48, Loss: 1.3329
Epoch 49, Loss: 1.2803
Create sweep with ID: vzy0n1jk
Sweep URL: https://wandb.ai/mm21b051-iitmaana/DeepLearning1/sweeps/vzy0n1jk
wandb: WARNING Calling wandb.login() after wandb.init() has no effect.
