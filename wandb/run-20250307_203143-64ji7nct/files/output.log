
Training with optimizer: adam
Epoch 0, Loss: 0.5480
Epoch 1, Loss: 0.4970
Epoch 2, Loss: 0.4619
Epoch 3, Loss: 0.4409
Epoch 4, Loss: 0.4262
Epoch 5, Loss: 0.4190
Epoch 6, Loss: 0.4082
Epoch 7, Loss: 0.3979
Epoch 8, Loss: 0.3902
Epoch 9, Loss: 0.3802
Epoch 10, Loss: 0.3741
Epoch 11, Loss: 0.3660
Epoch 12, Loss: 0.3575
Epoch 13, Loss: 0.3562
Epoch 14, Loss: 0.3464
Epoch 15, Loss: 0.3533
Epoch 16, Loss: 0.3410
Epoch 17, Loss: 0.3346
Epoch 18, Loss: 0.3360
Epoch 19, Loss: 0.3250
Epoch 20, Loss: 0.3180
Epoch 21, Loss: 0.3177
Epoch 22, Loss: 0.3122
Epoch 23, Loss: 0.3041
Epoch 24, Loss: 0.3027
Epoch 25, Loss: 0.3023
Epoch 26, Loss: 0.2959
Epoch 27, Loss: 0.2978
Epoch 28, Loss: 0.2883
Epoch 29, Loss: 0.2855
Epoch 30, Loss: 0.2835
Epoch 31, Loss: 0.2777
Epoch 32, Loss: 0.2761
Epoch 33, Loss: 0.2779
Epoch 34, Loss: 0.2712
Epoch 35, Loss: 0.2721
Epoch 36, Loss: 0.2750
Epoch 37, Loss: 0.2600
Epoch 38, Loss: 0.2626
Epoch 39, Loss: 0.2602
Epoch 40, Loss: 0.2524
Epoch 41, Loss: 0.2561
Epoch 42, Loss: 0.2479
Epoch 43, Loss: 0.2499
Epoch 44, Loss: 0.2426
Epoch 45, Loss: 0.2562
Epoch 46, Loss: 0.2369
Epoch 47, Loss: 0.2504
Epoch 48, Loss: 0.2371
Epoch 49, Loss: 0.2304
